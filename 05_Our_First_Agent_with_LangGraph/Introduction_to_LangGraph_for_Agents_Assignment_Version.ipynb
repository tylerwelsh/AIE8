{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "It happens when we run `model = model.bind_tools(tool_belt)`.\n",
        "\n",
        "The LangChain framework converts each tool in the tool belt into an OpenAI function calling format.\n",
        "\n",
        "Essentially it is taking the tool's name, description, and parameter schema. This is converted inot a JSON schema that is then attachend/sent along with every request to the LLM.\n",
        "\n",
        "The tool's description is the most important, essentially describing how it works and when it should be used. The  the LLM decides to use it or not based on these details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x12808c1a0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x12808c1a0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x12808c1a0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x12808c1a0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "Yes, the default is 25 steps. I found it in the docs: https://langchain-ai.github.io/langgraph/concepts/low_level/#recursion-limit\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "We could change the defualt limit to whatever went want by adding to the `config` param of the `invoke` method like so:\n",
        "config={\"recursion_limit\": 5}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4CbMADH6W38yKA7Czmph7wpp', 'function': {'arguments': '{\"query\":\"latest AI trends in 2025\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 163, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ71iBKFAh40XYQxxHFMvOXSPBaax', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--9958d409-62b8-445d-ba76-f19b86f52670-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'latest AI trends in 2025'}, 'id': 'call_4CbMADH6W38yKA7Czmph7wpp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 163, 'output_tokens': 24, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Five Transformative AI Technology Trends Shaping 2025 - Forbes\", \"url\": \"https://www.forbes.com/councils/forbestechcouncil/2025/04/15/five-transformative-ai-technology-trends-shaping-2025/\", \"content\": \"In 2025, we‚Äôre witnessing more than just smarter algorithms; we‚Äôre seeing the arrival of AI systems that learn while they work, autonomous agents that strategize like seasoned professionals and models small enough to fit in your pocket yet powerful enough to compete against supercomputers. These advancements aren‚Äôt isolated‚Äîthey‚Äôre converging to create AI that remembers, modifies and collaborates with human-like continuity. [...] Artificial intelligence technologies are changing faster than ever. What started as tools that could answer questions or generate images is now developing into systems that plan, adapt and collaborate like never before. Established giants like OpenAI and Google now share the stage with agile newcomers such as China‚Äôs DeepSeek‚Äîa rising star making waves with fresh approaches to how AI solves problems, proving that groundbreaking ideas can come from anywhere. [...] Based on my research experience and running an AI company, let‚Äôs explore the most important trends poised to reshape AI technologies in 2025.\\\\n\\\\n## 1. AI Agents\", \"score\": 0.8943568}, {\"title\": \"The Top Artificial Intelligence Trends - IBM\", \"url\": \"https://www.ibm.com/think/insights/artificial-intelligence-trends\", \"content\": \"Progress doesn\\'t necessarily require a constant influx of brand new ideas. Many of the most important AI trends in the first half of 2025 reflect changes in how the industry is applying existing ideas‚Äîsome pragmatic and productive, others less so.\\\\n\\\\n### Dramatic decrease in inference costs [...] This article primarily explores ongoing trends whose real-world impact might be realized on a horizon of months: in other words, trends with tangible impact mostly on or in the year 2025. There are, of course, other AI initiatives that are more evergreen and familiar. For example, though there has been recent movement on fully self-driving vehicles in isolated pockets‚Äîrobotaxi pilots have been launched in a handful of U.S. cities, with additional trials abroad in Oslo, Geneva and 16 Chinese [...] The future is always hard to predict. The breakneck pace of improvement in prior generations of AI models had many expecting the generation of models to be released in 2025 to make meaningful steps toward artificial general intelligence (AGI). While the latest models from OpenAI, Meta and the other most-funded players in the AI space are no doubt impressive, they‚Äôre certainly short of revolutionary.\", \"score\": 0.8909888}, {\"title\": \"AI trends 2025: Adoption barriers and updated predictions - Deloitte\", \"url\": \"https://www.deloitte.com/us/en/services/consulting/blogs/ai-adoption-challenges-ai-trends.html\", \"content\": \"Following the methodology used in our previous survey on these same topics, Deloitte invited AI leaders and decision-makers from various industries‚Äîas well as a wider LinkedIn audience‚Äîto share their perspectives on the most significant barriers facing their organizations.\\\\n\\\\nHere‚Äôs a summary of common adoption challenges for these AI trends in 2025, what people are saying and updated AI predictions for 2026.\\\\n\\\\nAgentic AI: From autonomy to alignment [...] ### Sovereign AI\\\\n\\\\n### Sovereign AI\\\\n\\\\n\\\\\\\\ Percentages may not total to 100% due to rounding\\\\n\\\\nLooking ahead: AI trends in 2025 and AI predictions for 2026\\\\n\\\\nIn our previous post, we anticipated growing momentum in autonomous systems, physical intelligence and regulatory uncertainty. These trends are now materializing:\\\\n\\\\n##### Agentic AI is evolving, but governance and business alignment are gating factors [...] deloitte_logo\\\\ndeloitte_logo\\\\n\\\\n### Blockchain & Digital Assets\\\\n\\\\n### Blockchain & Digital Assets\\\\n\\\\n### Blockchain & Digital Assets\\\\n\\\\n### Blockchain & Digital Assets\\\\n\\\\n### Blockchain & Digital Assets\\\\n\\\\nSelect your location\\\\n\\\\nNo results found\\\\n\\\\nIf we have selected the wrong experience for you, please change it above.\\\\n\\\\n# AI trends 2025: Adoption barriers and updated predictions\\\\n\\\\n## Enterprise challenges for agentic AI, physical AI and sovereign AI\", \"score\": 0.8815438}, {\"title\": \"5 AI Trends Shaping Innovation and ROI in 2025 | Morgan Stanley\", \"url\": \"https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt\", \"content\": \"## 1. AI Reasoning and Custom Silicon Fuel Demand for Chips\\\\n\\\\nAI reasoning is one of the biggest drivers of increasing compute demand, and thus semiconductors, said executives from companies that design and make chips. AI reasoning moves beyond basic understanding and into advanced learning and decision making, which requires additional compute for pre-training, post-training and inference. [...] Executives also highlighted the ‚Äúdata lakehouse revolution‚Äù‚Äîa trend to create unified data platforms that combine data lakes‚Äô low-cost storage and flexibility with data warehouses‚Äô structure and management features. This may involve partnerships with big corporations and other large tech companies in the AI ecosystem, to create best-of-breed AI and machine learning services for cloud integrations, cybersecurity, analytics, data sharing and industry-specific solutions. [...] The world‚Äôs biggest tech companies are vying to refine cutting-edge uses for artificial intelligence utilizations: large language models‚Äô ability to reason like humans; frontier models that push boundaries in natural-language processing, image generation, and coding; and the creation of systems that integrate multimodal data across text, images and video.\", \"score\": 0.87166095}, {\"title\": \"The 8 AI Trends For 2026 That Everyone Must Be Ready For Now\", \"url\": \"https://www.forbes.com/sites/bernardmarr/2025/09/22/the-8-biggest-ai-trends-for-2026-that-everyone-must-be-ready-for-now/\", \"content\": \"Agentic AI has undoubtedly been the hot buzzword of 2025, and 2026 will be the year that the effects of these autonomous, action-taking assistants really take shape. Imagine ChatGPT, but as well as answering questions and generating content, it can take on day-to-day tasks like ordering groceries, making travel arrangements or even interacting with smart-home devices to manage household tasks. In the workplace, AI will graduate from offering assistance to coordinating and delivering complex\", \"score\": 0.81979275}]', name='tavily_search_results_json', id='a97c0e29-79da-45ef-802b-9b6b5d084ea7', tool_call_id='call_4CbMADH6W38yKA7Czmph7wpp', artifact={'query': 'latest AI trends in 2025', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.forbes.com/councils/forbestechcouncil/2025/04/15/five-transformative-ai-technology-trends-shaping-2025/', 'title': 'Five Transformative AI Technology Trends Shaping 2025 - Forbes', 'content': 'In 2025, we‚Äôre witnessing more than just smarter algorithms; we‚Äôre seeing the arrival of AI systems that learn while they work, autonomous agents that strategize like seasoned professionals and models small enough to fit in your pocket yet powerful enough to compete against supercomputers. These advancements aren‚Äôt isolated‚Äîthey‚Äôre converging to create AI that remembers, modifies and collaborates with human-like continuity. [...] Artificial intelligence technologies are changing faster than ever. What started as tools that could answer questions or generate images is now developing into systems that plan, adapt and collaborate like never before. Established giants like OpenAI and Google now share the stage with agile newcomers such as China‚Äôs DeepSeek‚Äîa rising star making waves with fresh approaches to how AI solves problems, proving that groundbreaking ideas can come from anywhere. [...] Based on my research experience and running an AI company, let‚Äôs explore the most important trends poised to reshape AI technologies in 2025.\\n\\n## 1. AI Agents', 'score': 0.8943568, 'raw_content': None}, {'url': 'https://www.ibm.com/think/insights/artificial-intelligence-trends', 'title': 'The Top Artificial Intelligence Trends - IBM', 'content': \"Progress doesn't necessarily require a constant influx of brand new ideas. Many of the most important AI trends in the first half of 2025 reflect changes in how the industry is applying existing ideas‚Äîsome pragmatic and productive, others less so.\\n\\n### Dramatic decrease in inference costs [...] This article primarily explores ongoing trends whose real-world impact might be realized on a horizon of months: in other words, trends with tangible impact mostly on or in the year 2025. There are, of course, other AI initiatives that are more evergreen and familiar. For example, though there has been recent movement on fully self-driving vehicles in isolated pockets‚Äîrobotaxi pilots have been launched in a handful of U.S. cities, with additional trials abroad in Oslo, Geneva and 16 Chinese [...] The future is always hard to predict. The breakneck pace of improvement in prior generations of AI models had many expecting the generation of models to be released in 2025 to make meaningful steps toward artificial general intelligence (AGI). While the latest models from OpenAI, Meta and the other most-funded players in the AI space are no doubt impressive, they‚Äôre certainly short of revolutionary.\", 'score': 0.8909888, 'raw_content': None}, {'url': 'https://www.deloitte.com/us/en/services/consulting/blogs/ai-adoption-challenges-ai-trends.html', 'title': 'AI trends 2025: Adoption barriers and updated predictions - Deloitte', 'content': 'Following the methodology used in our previous survey on these same topics, Deloitte invited AI leaders and decision-makers from various industries‚Äîas well as a wider LinkedIn audience‚Äîto share their perspectives on the most significant barriers facing their organizations.\\n\\nHere‚Äôs a summary of common adoption challenges for these AI trends in 2025, what people are saying and updated AI predictions for 2026.\\n\\nAgentic AI: From autonomy to alignment [...] ### Sovereign AI\\n\\n### Sovereign AI\\n\\n\\\\ Percentages may not total to 100% due to rounding\\n\\nLooking ahead: AI trends in 2025 and AI predictions for 2026\\n\\nIn our previous post, we anticipated growing momentum in autonomous systems, physical intelligence and regulatory uncertainty. These trends are now materializing:\\n\\n##### Agentic AI is evolving, but governance and business alignment are gating factors [...] deloitte_logo\\ndeloitte_logo\\n\\n### Blockchain & Digital Assets\\n\\n### Blockchain & Digital Assets\\n\\n### Blockchain & Digital Assets\\n\\n### Blockchain & Digital Assets\\n\\n### Blockchain & Digital Assets\\n\\nSelect your location\\n\\nNo results found\\n\\nIf we have selected the wrong experience for you, please change it above.\\n\\n# AI trends 2025: Adoption barriers and updated predictions\\n\\n## Enterprise challenges for agentic AI, physical AI and sovereign AI', 'score': 0.8815438, 'raw_content': None}, {'url': 'https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt', 'title': '5 AI Trends Shaping Innovation and ROI in 2025 | Morgan Stanley', 'content': '## 1. AI Reasoning and Custom Silicon Fuel Demand for Chips\\n\\nAI reasoning is one of the biggest drivers of increasing compute demand, and thus semiconductors, said executives from companies that design and make chips. AI reasoning moves beyond basic understanding and into advanced learning and decision making, which requires additional compute for pre-training, post-training and inference. [...] Executives also highlighted the ‚Äúdata lakehouse revolution‚Äù‚Äîa trend to create unified data platforms that combine data lakes‚Äô low-cost storage and flexibility with data warehouses‚Äô structure and management features. This may involve partnerships with big corporations and other large tech companies in the AI ecosystem, to create best-of-breed AI and machine learning services for cloud integrations, cybersecurity, analytics, data sharing and industry-specific solutions. [...] The world‚Äôs biggest tech companies are vying to refine cutting-edge uses for artificial intelligence utilizations: large language models‚Äô ability to reason like humans; frontier models that push boundaries in natural-language processing, image generation, and coding; and the creation of systems that integrate multimodal data across text, images and video.', 'score': 0.87166095, 'raw_content': None}, {'url': 'https://www.forbes.com/sites/bernardmarr/2025/09/22/the-8-biggest-ai-trends-for-2026-that-everyone-must-be-ready-for-now/', 'title': 'The 8 AI Trends For 2026 That Everyone Must Be Ready For Now', 'content': 'Agentic AI has undoubtedly been the hot buzzword of 2025, and 2026 will be the year that the effects of these autonomous, action-taking assistants really take shape. Imagine ChatGPT, but as well as answering questions and generating content, it can take on day-to-day tasks like ordering groceries, making travel arrangements or even interacting with smart-home devices to manage household tasks. In the workplace, AI will graduate from offering assistance to coordinating and delivering complex', 'score': 0.81979275, 'raw_content': None}], 'response_time': 3.93, 'request_id': 'd2e21fff-1d43-4ffc-8db0-b5d54eb630a4'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The latest AI trends in 2025 include several transformative developments:\\n\\n1. AI Agents: Autonomous agents that strategize, learn, and collaborate with human-like continuity are becoming prominent. These agents are capable of planning, adapting, and working alongside humans in more sophisticated ways.\\n\\n2. AI Reasoning and Frontier Models: AI systems are increasingly capable of advanced reasoning, decision-making, and reasoning like humans. This includes the development of frontier models that push the boundaries in natural language processing, image generation, and multimodal data integration.\\n\\n3. Autonomous and Physical AI: There is a growing focus on autonomous systems, including self-driving vehicles and physical intelligence, with ongoing efforts to address governance and alignment challenges.\\n\\n4. Cost Reduction and Efficiency: Significant decreases in inference costs are making AI more accessible and practical for widespread use.\\n\\n5. AI in Industry and Data Platforms: The creation of unified data platforms, such as data lakehouses, is revolutionizing how organizations manage and utilize data for AI applications.\\n\\n6. Agentic AI and Automation: The concept of agentic AI is evolving, with AI systems taking on more complex tasks like managing household chores, travel arrangements, and workplace coordination.\\n\\n7. Industry-Specific AI Solutions: Companies are developing tailored AI solutions for various sectors, leveraging multimodal data and advanced models.\\n\\n8. Regulatory and Ethical Considerations: As AI capabilities expand, governance, alignment, and regulatory frameworks are becoming critical areas of focus.\\n\\nOverall, AI in 2025 is characterized by increased autonomy, reasoning capabilities, cost efficiency, and integration into daily life and industry operations.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 316, 'prompt_tokens': 1546, 'total_tokens': 1862, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ71m7BgiCNZhcHrzrRcEEdP9EUEV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5125f91f-a04e-4a89-bd97-a64331b77fce-0', usage_metadata={'input_tokens': 1546, 'output_tokens': 316, 'total_tokens': 1862, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
        "\n",
        "# I needed a more precise questions where it felt it needed to use the tools.\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"What are the latest AI trends in 2025?\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_givL2GsCYvC7NZj2J8Hl1yj1', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_35y5ynwQkKmguvhgZwoKjh98', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research paper\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 182, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73An3L0hHZQOPvcuQuXGfhjd3ZW', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4515e093-6840-42c1-a63e-ba1dc6d2728c-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_givL2GsCYvC7NZj2J8Hl1yj1', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research paper'}, 'id': 'call_35y5ynwQkKmguvhgZwoKjh98', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 59, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='c2f48b19-1489-4256-b33b-18b5333d3754', tool_call_id='call_givL2GsCYvC7NZj2J8Hl1yj1'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"|  |  |\\\\n --- |\\\\n| Comments: | 95 pages, 11 figures |\\\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\\\n| ACM classes: | I.2.8 |\\\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\\\n|  |  arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through\", \"score\": 0.88822687}, {\"title\": \"[PDF] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).\", \"score\": 0.8033131}, {\"title\": \"A comprehensive survey of deep learning research on medical ...\", \"url\": \"https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856\", \"content\": \"Skip to main contentSkip to article\\\\n\\\\nSign in\\\\n\\\\n Access through your organization\\\\n Purchase PDF\\\\n Patient Access\\\\n\\\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\\\n\\\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\\\n  \\\\n  \\\\nYou may also be able to exercise your privacy choices as described in our Privacy Policy\", \"score\": 0.5521781}, {\"title\": \"Top Research Papers on Deep Learning - Must Read List\", \"url\": \"https://paperguide.ai/papers/top/research-papers-deep-learning/\", \"content\": \"This is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support and the seminal work there.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Reading, Deep Learning\\\\n2 Citations 2022\\\\n\\\\nauthors unavailable\\\\n\\\\njournal unavailable [...] This paper surveys comprehensively recent advances in deep class-incremental learning and summarizes these methods from three aspects, i.e. , data-centric, model-centric, and algorithm-centric, and provides a rigorous and uniÔ¨Åed evaluation of 16 methods in benchmark image class-incremental learning tasks to find out the characteristics of different algorithms empirically.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Learning with Logical Constraints\\\\n62 Citations 2022 [...] IEEE Access\\\\n\\\\nThis paper comprehensively discussed the attacks and defenses in four popular DL models, including DNN, DRL, FL, and TL, and highlighted the application domains, datasets, metrics, and testbeds in these fields.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Class-Incremental Learning: A Survey\\\\n103 Citations 2023\\\\n\\\\nDa-Wei Zhou, Qiwen Wang, Zhi-Hong Qi + 3 more\\\\n\\\\nArXiv\", \"score\": 0.46337196}, {\"title\": \"Deep Research Tools: A Comprehensive Guide and Comparison\", \"url\": \"https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122\", \"content\": \"refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] ## Report Quality (Depth, Structure, Accuracy, Relevance)\\\\n\\\\nOne of the biggest considerations when choosing a deep research tool is the quality of the report or output it generates. Does it produce in-depth content or just superficial summaries? Are its reports well-structured and coherent? Does it stay accurate and cite relevant sources? Here‚Äôs how each tool fares: [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).\", \"score\": 0.45551404}]', name='tavily_search_results_json', id='ae6e0553-c3ce-477a-9db1-d67c035ca66a', tool_call_id='call_35y5ynwQkKmguvhgZwoKjh98', artifact={'query': 'A Comprehensive Survey of Deep Research paper', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research - arXiv', 'content': '|  |  |\\n --- |\\n| Comments: | 95 pages, 11 figures |\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\n| ACM classes: | I.2.8 |\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\n|  |  arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\n\\nFull-text links:\\n\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through', 'score': 0.88822687, 'raw_content': None}, {'url': 'https://arxiv.org/pdf/2506.12594?', 'title': '[PDF] A Comprehensive Survey of Deep Research - arXiv', 'content': 'Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).', 'score': 0.8033131, 'raw_content': None}, {'url': 'https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856', 'title': 'A comprehensive survey of deep learning research on medical ...', 'content': 'Skip to main contentSkip to article\\n\\nSign in\\n\\n Access through your organization\\n Purchase PDF\\n Patient Access\\n\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\n\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\n  \\n  \\nYou may also be able to exercise your privacy choices as described in our Privacy Policy', 'score': 0.5521781, 'raw_content': None}, {'url': 'https://paperguide.ai/papers/top/research-papers-deep-learning/', 'title': 'Top Research Papers on Deep Learning - Must Read List', 'content': 'This is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support and the seminal work there.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Reading, Deep Learning\\n2 Citations 2022\\n\\nauthors unavailable\\n\\njournal unavailable [...] This paper surveys comprehensively recent advances in deep class-incremental learning and summarizes these methods from three aspects, i.e. , data-centric, model-centric, and algorithm-centric, and provides a rigorous and uniÔ¨Åed evaluation of 16 methods in benchmark image class-incremental learning tasks to find out the characteristics of different algorithms empirically.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Learning with Logical Constraints\\n62 Citations 2022 [...] IEEE Access\\n\\nThis paper comprehensively discussed the attacks and defenses in four popular DL models, including DNN, DRL, FL, and TL, and highlighted the application domains, datasets, metrics, and testbeds in these fields.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Class-Incremental Learning: A Survey\\n103 Citations 2023\\n\\nDa-Wei Zhou, Qiwen Wang, Zhi-Hong Qi + 3 more\\n\\nArXiv', 'score': 0.46337196, 'raw_content': None}, {'url': 'https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122', 'title': 'Deep Research Tools: A Comprehensive Guide and Comparison', 'content': 'refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] ## Report Quality (Depth, Structure, Accuracy, Relevance)\\n\\nOne of the biggest considerations when choosing a deep research tool is the quality of the report or output it generates. Does it produce in-depth content or just superficial summaries? Are its reports well-structured and coherent? Does it stay accurate and cite relevant sources? Here‚Äôs how each tool fares: [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).', 'score': 0.45551404, 'raw_content': None}], 'response_time': 1.63, 'request_id': '41cc526b-2883-4ac7-b1b3-3a7b9a670c5b'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" was published on June 14, 2025, authored by Renjun Xu and Jingwen Peng. \\n\\nI will now proceed to find out where the authors currently work.', additional_kwargs={'tool_calls': [{'id': 'call_ObzZFG5aVf8NAxQ058eg2d8h', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_KuvSnvV0DYPgSAFZMnxAqYLV', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 2574, 'total_tokens': 2686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73FKxf4Lf7DrH1et8k043TYbhAd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8fb80e27-78e4-421a-9c5e-9f702ae7cc23-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_ObzZFG5aVf8NAxQ058eg2d8h', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_KuvSnvV0DYPgSAFZMnxAqYLV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2574, 'output_tokens': 112, 'total_tokens': 2686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: tavily_search_results_json\n",
            "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University - OpenReview\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n#### Names\\\\n\\\\n#### Emails\\\\n\\\\n#### Personal Links\\\\n\\\\n#### Career & Education History\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n#### Expertise\\\\n\\\\n#### Publications\\\\n\\\\n#### scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics)\\\\n\\\\n#### $E(2)$-Equivariant Vision Transformer)\\\\n\\\\n#### Critical Temperature Prediction of Superconductors Based on Machine Learning: A Short Review) [...] #### Exploiting Adapters for Cross-Lingual Low-Resource Speech Recognition)\\\\n\\\\n#### Hierarchical knowledge amalgamation with dual discriminative feature alignment)\\\\n\\\\n#### Modeling Dynamic Missingness of Implicit Feedback for Sequential Recommendation)\\\\n\\\\n#### S2SNet: A Pretrained Neural Network for Superconductivity Discovery)\\\\n\\\\n#### Learning Interest-oriented Universal User Representation via Self-supervision) [...] #### Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling)\\\\n\\\\n#### Learning Invariant Representations across Domains and Tasks)\\\\n\\\\n#### Co-Authors\\\\n\\\\nOpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors. ¬© 2025 OpenReview\", \"score\": 0.6410185}, {\"title\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè\", \"url\": \"https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1\", \"content\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\\\n\\\\n\\\\n\\\\nResearch\\\\n\\\\nCenter for Data Science Zhejiang University\\\\n\\\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\\\n\\\\nEducation\\\\n\\\\nSign in to view more\\\\n\\\\nExperience\\\\n\\\\nSign in to view more [...] Research Interests\\\\n\\\\n2012 2025\\\\n\\\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\\\n\\\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\\\n\\\\nÊó∂Èó¥\\\\n\\\\nÂºïÁî®Èáè\\\\n\\\\n‰∏ªÈ¢ò\\\\n\\\\nÊúüÂàäÁ∫ßÂà´\\\\n\\\\nÂêà‰ΩúËÄÖ\\\\n\\\\nÂêà‰ΩúÊú∫ÊûÑ\\\\n\\\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\\\n\\\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\\\n\\\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\\\n\\\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\\\n\\\\nCited 0 Views 11 Bibtex\\\\n\\\\n0\\\\n\\\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\\\n\\\\nSwipe to Fine Result\", \"score\": 0.60049355}, {\"title\": \"Renjun Hu\\'s Homepage\", \"url\": \"https://hurenjun.github.io/\", \"content\": \"an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across various business\\\\ndomains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge.\\\\nSince January 2025, he has joined the School of Data Science and Engineering, East China Normal University\\\\nas a young researcher.\\\\nHis recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor\\'s degree in 2014 and Ph.D. in 2020 from the School of Computer Science\\\\nand Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student\\\\nin the Data Mining Group at Rutgers University. He then worked as a research intern at the Business\\\\nIntelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as [...] Renjun\\'s avatar\\\\n\\\\n### Renjun Hu     (ËÉ°‰ªÅÂêõ)\\\\n\\\\n#### Young Researcher\\\\n\\\\nSchool of Data Science of Engineering (DaSE)  \\\\nEast China Normal University (ECNU)\\\\n\\\\n \\\\nRoom X109, Shuxueguan, Putuo Campus\\\\n\\\\n \\\\nrjhu [at] dase.ecnu.edu.cn    renjun0hu [at] gmail.com\\\\n\\\\n### Short Bio\", \"score\": 0.59880555}, {\"title\": \"Renjun XU | UCD | Department of Physics | Research profile\", \"url\": \"https://www.researchgate.net/profile/Renjun-Xu\", \"content\": \"Skills and Expertise: Electronic Structure. Current institution: University of California, Davis. University of California, Davis.\", \"score\": 0.5683445}, {\"title\": \"Xu Genjun - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Xu_Genjun\", \"content\": \"Xu was born in She County, Anhui on 23 November 1935. He graduated from the Chemistry Department of Fudan University in 1957, and joined the Shanghai Institute of Biochemistry afterwards, where he participated in and made significant contributions to the insulin synthesis project led by Wang Yinglai. He later researched enzyme kinetics, chemical modification of proteins, the relationship between proteins\\' structure and function, and the folding and refolding of proteins. [...] Xu published more than 100 research papers in academic journals. He was a two-time winner of the State Natural Science Award (first class), in addition to several national prizes by the Chinese Academy of Sciences (CAS). He was also awarded the Ho Leung Ho Lee Prize for Life Sciences. He was elected as an academician of the CAS in 1991.\\\\n\\\\nXu died on 8 January 2008 at Zhongshan Hospital in Shanghai, at the age of 72.\\\\n\\\\n## References\\\\n\\\\nWikimedia Foundation\\\\nPowered by MediaWiki [...] Wikipedia\\\\nThe Free Encyclopedia\\\\n\\\\n## Contents\\\\n\\\\n# Xu Genjun\\\\n\\\\nXu Genjun (Chinese: ËÆ∏Ê†π‰øä; 23 November 1935 ‚Äì 8 January 2008) was a Chinese biochemist. He was a professor at the Shanghai Institute of Biochemistry and Cell Biology. He was an academician of the Chinese Academy of Sciences and President of the Chinese Society of Biochemistry and Molecular Biology.\\\\n\\\\n## Biography\", \"score\": 0.25375047}]', name='tavily_search_results_json', id='c5b33580-a980-4716-9472-ee857af9f2cc', tool_call_id='call_ObzZFG5aVf8NAxQ058eg2d8h', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University - OpenReview', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n#### Names\\n\\n#### Emails\\n\\n#### Personal Links\\n\\n#### Career & Education History\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n#### Expertise\\n\\n#### Publications\\n\\n#### scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics)\\n\\n#### $E(2)$-Equivariant Vision Transformer)\\n\\n#### Critical Temperature Prediction of Superconductors Based on Machine Learning: A Short Review) [...] #### Exploiting Adapters for Cross-Lingual Low-Resource Speech Recognition)\\n\\n#### Hierarchical knowledge amalgamation with dual discriminative feature alignment)\\n\\n#### Modeling Dynamic Missingness of Implicit Feedback for Sequential Recommendation)\\n\\n#### S2SNet: A Pretrained Neural Network for Superconductivity Discovery)\\n\\n#### Learning Interest-oriented Universal User Representation via Self-supervision) [...] #### Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling)\\n\\n#### Learning Invariant Representations across Domains and Tasks)\\n\\n#### Co-Authors\\n\\nOpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors. ¬© 2025 OpenReview', 'score': 0.6410185, 'raw_content': None}, {'url': 'https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1', 'title': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè', 'content': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\n\\n\\n\\nResearch\\n\\nCenter for Data Science Zhejiang University\\n\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\n\\nEducation\\n\\nSign in to view more\\n\\nExperience\\n\\nSign in to view more [...] Research Interests\\n\\n2012 2025\\n\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\n\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\n\\nÊó∂Èó¥\\n\\nÂºïÁî®Èáè\\n\\n‰∏ªÈ¢ò\\n\\nÊúüÂàäÁ∫ßÂà´\\n\\nÂêà‰ΩúËÄÖ\\n\\nÂêà‰ΩúÊú∫ÊûÑ\\n\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\n\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\n\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\n\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\n\\nCited 0 Views 11 Bibtex\\n\\n0\\n\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\n\\nSwipe to Fine Result', 'score': 0.60049355, 'raw_content': None}, {'url': 'https://hurenjun.github.io/', 'title': \"Renjun Hu's Homepage\", 'content': \"an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across various business\\ndomains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge.\\nSince January 2025, he has joined the School of Data Science and Engineering, East China Normal University\\nas a young researcher.\\nHis recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor's degree in 2014 and Ph.D. in 2020 from the School of Computer Science\\nand Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student\\nin the Data Mining Group at Rutgers University. He then worked as a research intern at the Business\\nIntelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as [...] Renjun's avatar\\n\\n### Renjun Hu     (ËÉ°‰ªÅÂêõ)\\n\\n#### Young Researcher\\n\\nSchool of Data Science of Engineering (DaSE)  \\nEast China Normal University (ECNU)\\n\\n \\nRoom X109, Shuxueguan, Putuo Campus\\n\\n \\nrjhu [at] dase.ecnu.edu.cn    renjun0hu [at] gmail.com\\n\\n### Short Bio\", 'score': 0.59880555, 'raw_content': None}, {'url': 'https://www.researchgate.net/profile/Renjun-Xu', 'title': 'Renjun XU | UCD | Department of Physics | Research profile', 'content': 'Skills and Expertise: Electronic Structure. Current institution: University of California, Davis. University of California, Davis.', 'score': 0.5683445, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Xu_Genjun', 'title': 'Xu Genjun - Wikipedia', 'content': \"Xu was born in She County, Anhui on 23 November 1935. He graduated from the Chemistry Department of Fudan University in 1957, and joined the Shanghai Institute of Biochemistry afterwards, where he participated in and made significant contributions to the insulin synthesis project led by Wang Yinglai. He later researched enzyme kinetics, chemical modification of proteins, the relationship between proteins' structure and function, and the folding and refolding of proteins. [...] Xu published more than 100 research papers in academic journals. He was a two-time winner of the State Natural Science Award (first class), in addition to several national prizes by the Chinese Academy of Sciences (CAS). He was also awarded the Ho Leung Ho Lee Prize for Life Sciences. He was elected as an academician of the CAS in 1991.\\n\\nXu died on 8 January 2008 at Zhongshan Hospital in Shanghai, at the age of 72.\\n\\n## References\\n\\nWikimedia Foundation\\nPowered by MediaWiki [...] Wikipedia\\nThe Free Encyclopedia\\n\\n## Contents\\n\\n# Xu Genjun\\n\\nXu Genjun (Chinese: ËÆ∏Ê†π‰øä; 23 November 1935 ‚Äì 8 January 2008) was a Chinese biochemist. He was a professor at the Shanghai Institute of Biochemistry and Cell Biology. He was an academician of the Chinese Academy of Sciences and President of the Chinese Society of Biochemistry and Molecular Biology.\\n\\n## Biography\", 'score': 0.25375047, 'raw_content': None}], 'response_time': 1.67, 'request_id': '55198a01-11b8-40ed-bd45-2ad774234b55'}), ToolMessage(content='[{\"title\": \"Jingwen Peng, CFA - Director - Lead Data Steward at Liberty Mutual ...\", \"url\": \"https://www.linkedin.com/in/jingwen-peng-cfa-3a69b011?trk=public_profile_browsemap\", \"content\": \"Director - Lead Data Steward at Liberty Mutual Investments ¬∑ Experience: Liberty Mutual Investments ¬∑ Location: Boston ¬∑ 500+ connections on LinkedIn.\", \"score\": 0.70823324}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\\\n### Marketing Analyst  \\\\nEmpire City Casino  \\\\nMay 2025 - Present   \\\\nYonkers, New York, United States  \\\\n\\\\n### Amazon  \\\\nAmazon  \\\\nN/A - Present   \\\\nBeijing, China  \\\\n\\\\n### Marketing Analyst  \\\\nJiyuzhoutian Information Technology  \\\\nApr 2019 - Sep 2019   \\\\nBeijing, China  \\\\n‚óè\\\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.\", \"score\": 0.6301622}, {\"title\": \"[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018\", \"url\": \"https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf\", \"content\": \"Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE [...] over 10 villages in 4 provinces, interviewing over 600 people. He was appointed Academic Organizer of the China Youth Economic Forum and also served as the President of the Student Union of the School of Economics and the Chairman of the Standing Committee of the Students‚Äô Congress. Peng is 22 years old and from China. PRESTON LIM CANADA PRINCETON UNIVERSITY Preston graduated in June 2017 from Princeton University with a major in Near Eastern Studies and a minor in History and the Practice of\", \"score\": 0.38366494}, {\"title\": \"Professor Peng GONG - GEOG | HKU\", \"url\": \"https://geog.hku.hk/p-gong\", \"content\": \"Guan, D.\\\\\\\\, Wang, D., Hallegatte, S. Steven J. Davis, Jingwen Huo, Shuping Li, Yangchun Bai, Tianyang Lei, Qianyu Xue, D‚ÄôMaris Coffman, Danyang Cheng, Peipei Chen, Xi Liang, Bing Xu, Xiaosheng Lu, Shouyang Wang, Klaus Hubacek & Peng Gong. Global supply-chain effects of COVID-19 control measures. Nature Human Behaviour (2020). 4(6):577-587. . [...] Gong, P\\\\\\\\, Bin Chen, Xuecao Li, Han Liu, JieWang, Yuqi Bai, Jingming Chen, Xi Chen, Lei Fang, Shuailong Feng, Yongjiu Feng, Yali Gong, Hao Gu, Huabing Huang, Xiaochun Huang, Hongzan Jiao, Yingdong Kang, Guangbin Lei, Ainong Li, Xiaoting Li, Xun Li, Yuechen Li, Zhilin Li, Zhongde Li, Chong Liu, Chunxia Liu, Maochou Liu, Shuguang Liu, Wanliu Mao, Changhong Miao, Hao Ni, Qisheng Pan, Shuhua Qi, Zhehao Ren, Zhuoran Shan, Shaoqing Shen, Minjun Shi, Yimeng Song, Mo Su, HoiPing Suen, Bo Sun, Fangdi [...] Beijing Normal University, and the Tsinghua Urban Institute at Tsinghua University. In 2020, he led an expert preparation group in establishing the Vanke School of Public Health at Tsinghua.\", \"score\": 0.30464175}, {\"title\": \"Investigators | Center for Computational Biology and Bioinformatics\", \"url\": \"https://medicine.iu.edu/research-centers/computational-biology-bioinformatics/investigators\", \"content\": \"Associate Professor of Bioinformatics and Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Bohdan Khomtchouk, PhD\\\\n\\\\nAssistant Professor of Bioinformatics and Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Juexin Wang, PhD\\\\n\\\\nAssistant Professor of Bioinformatics\\\\n\\\\nRead Bio\\\\n\\\\n### Jingwen Yan, PhD\\\\n\\\\nAssistant Professor of Bioinformatics\\\\n\\\\nRead Bio\\\\n\\\\n### IU Bloomington Luddy School of Informatics, Computing and Engineering\\\\n\\\\n### Yijie Wang, PhD\\\\n\\\\nAssistant Professor of Computer Science\\\\n\\\\nRead Bio\\\\n\\\\n### Purdue University in Indianapolis [...] ### Jing Liu, PhD\\\\n\\\\nAssistant Professor of Physics\\\\n\\\\nRead Bio\\\\n\\\\n## Associate Members\\\\n\\\\nJunior computational scientists conducting research in quantitative biomedical sciences\\\\n\\\\n### Xiaoqing Huang, PhD\\\\n\\\\nAssistant Research Professor of Biostatistics & Health Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Gang Peng, PhD\\\\n\\\\nAssistant Professor of Medical & Molecular Genetics\\\\n\\\\nRead Bio\\\\n\\\\n### Jie Ren, PhD\\\\n\\\\nAssistant Professor of Biostatistics & Health Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Tae-Hwi L. Schwantes-An, PhD [...] Professor of Biochemistry & Molecular Biology\\\\n\\\\nRead Bio\\\\n\\\\n### Ian Webb, PhD\\\\n\\\\nAssistant Professor, Department of Chemistry & Chemical Biology\\\\n\\\\nRead Bio\\\\n\\\\n### Kai Yang, PhD\\\\n\\\\nAssociate Professor of Pediatrics\\\\n\\\\nRead Bio\\\\n\\\\n### Lei Yang, PhD\\\\n\\\\nProfessor of Pediatrics\\\\n\\\\nRead Bio\\\\n\\\\n### Ji Zhang, PhD\\\\n\\\\nAssociate Professor of Pediatrics\\\\n\\\\nRead Bio\", \"score\": 0.19255488}]', name='tavily_search_results_json', id='2efa1c1e-58d6-4af2-8c57-ea2e8323e1c1', tool_call_id='call_KuvSnvV0DYPgSAFZMnxAqYLV', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.linkedin.com/in/jingwen-peng-cfa-3a69b011?trk=public_profile_browsemap', 'title': 'Jingwen Peng, CFA - Director - Lead Data Steward at Liberty Mutual ...', 'content': 'Director - Lead Data Steward at Liberty Mutual Investments ¬∑ Experience: Liberty Mutual Investments ¬∑ Location: Boston ¬∑ 500+ connections on LinkedIn.', 'score': 0.70823324, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn', 'content': '‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\n### Marketing Analyst  \\nEmpire City Casino  \\nMay 2025 - Present   \\nYonkers, New York, United States  \\n\\n### Amazon  \\nAmazon  \\nN/A - Present   \\nBeijing, China  \\n\\n### Marketing Analyst  \\nJiyuzhoutian Information Technology  \\nApr 2019 - Sep 2019   \\nBeijing, China  \\n‚óè\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.', 'score': 0.6301622, 'raw_content': None}, {'url': 'https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf', 'title': '[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018', 'content': 'Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE [...] over 10 villages in 4 provinces, interviewing over 600 people. He was appointed Academic Organizer of the China Youth Economic Forum and also served as the President of the Student Union of the School of Economics and the Chairman of the Standing Committee of the Students‚Äô Congress. Peng is 22 years old and from China. PRESTON LIM CANADA PRINCETON UNIVERSITY Preston graduated in June 2017 from Princeton University with a major in Near Eastern Studies and a minor in History and the Practice of', 'score': 0.38366494, 'raw_content': None}, {'url': 'https://geog.hku.hk/p-gong', 'title': 'Professor Peng GONG - GEOG | HKU', 'content': 'Guan, D.\\\\, Wang, D., Hallegatte, S. Steven J. Davis, Jingwen Huo, Shuping Li, Yangchun Bai, Tianyang Lei, Qianyu Xue, D‚ÄôMaris Coffman, Danyang Cheng, Peipei Chen, Xi Liang, Bing Xu, Xiaosheng Lu, Shouyang Wang, Klaus Hubacek & Peng Gong. Global supply-chain effects of COVID-19 control measures. Nature Human Behaviour (2020). 4(6):577-587. . [...] Gong, P\\\\, Bin Chen, Xuecao Li, Han Liu, JieWang, Yuqi Bai, Jingming Chen, Xi Chen, Lei Fang, Shuailong Feng, Yongjiu Feng, Yali Gong, Hao Gu, Huabing Huang, Xiaochun Huang, Hongzan Jiao, Yingdong Kang, Guangbin Lei, Ainong Li, Xiaoting Li, Xun Li, Yuechen Li, Zhilin Li, Zhongde Li, Chong Liu, Chunxia Liu, Maochou Liu, Shuguang Liu, Wanliu Mao, Changhong Miao, Hao Ni, Qisheng Pan, Shuhua Qi, Zhehao Ren, Zhuoran Shan, Shaoqing Shen, Minjun Shi, Yimeng Song, Mo Su, HoiPing Suen, Bo Sun, Fangdi [...] Beijing Normal University, and the Tsinghua Urban Institute at Tsinghua University. In 2020, he led an expert preparation group in establishing the Vanke School of Public Health at Tsinghua.', 'score': 0.30464175, 'raw_content': None}, {'url': 'https://medicine.iu.edu/research-centers/computational-biology-bioinformatics/investigators', 'title': 'Investigators | Center for Computational Biology and Bioinformatics', 'content': 'Associate Professor of Bioinformatics and Data Science\\n\\nRead Bio\\n\\n### Bohdan Khomtchouk, PhD\\n\\nAssistant Professor of Bioinformatics and Data Science\\n\\nRead Bio\\n\\n### Juexin Wang, PhD\\n\\nAssistant Professor of Bioinformatics\\n\\nRead Bio\\n\\n### Jingwen Yan, PhD\\n\\nAssistant Professor of Bioinformatics\\n\\nRead Bio\\n\\n### IU Bloomington Luddy School of Informatics, Computing and Engineering\\n\\n### Yijie Wang, PhD\\n\\nAssistant Professor of Computer Science\\n\\nRead Bio\\n\\n### Purdue University in Indianapolis [...] ### Jing Liu, PhD\\n\\nAssistant Professor of Physics\\n\\nRead Bio\\n\\n## Associate Members\\n\\nJunior computational scientists conducting research in quantitative biomedical sciences\\n\\n### Xiaoqing Huang, PhD\\n\\nAssistant Research Professor of Biostatistics & Health Data Science\\n\\nRead Bio\\n\\n### Gang Peng, PhD\\n\\nAssistant Professor of Medical & Molecular Genetics\\n\\nRead Bio\\n\\n### Jie Ren, PhD\\n\\nAssistant Professor of Biostatistics & Health Data Science\\n\\nRead Bio\\n\\n### Tae-Hwi L. Schwantes-An, PhD [...] Professor of Biochemistry & Molecular Biology\\n\\nRead Bio\\n\\n### Ian Webb, PhD\\n\\nAssistant Professor, Department of Chemistry & Chemical Biology\\n\\nRead Bio\\n\\n### Kai Yang, PhD\\n\\nAssociate Professor of Pediatrics\\n\\nRead Bio\\n\\n### Lei Yang, PhD\\n\\nProfessor of Pediatrics\\n\\nRead Bio\\n\\n### Ji Zhang, PhD\\n\\nAssociate Professor of Pediatrics\\n\\nRead Bio', 'score': 0.19255488, 'raw_content': None}], 'response_time': 1.63, 'request_id': '429125b7-11e4-4b4c-8cff-22a6734a27c4'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Renjun Xu is currently a Principal Researcher at Zhejiang University and also associated with the Center for Data Science at Zhejiang University. Jingwen Peng is a Director and Lead Data Steward at Liberty Mutual Investments in Boston.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 6331, 'total_tokens': 6374, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2560}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73IQm6GxBQWegjfZQiI2Czy1e7O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--df884874-cc42-4bb4-ae70-588654a0f6be-0', usage_metadata={'input_tokens': 6331, 'output_tokens': 43, 'total_tokens': 6374, 'input_token_details': {'audio': 0, 'cache_read': 2560}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer.\n",
        "\n",
        "##### ‚úÖ Answer:\n",
        "\n",
        "Agent:\n",
        "- From the tools it realzied it needs to use both Arxiv and Tavily tools\n",
        "- Made calls to both with the query \"A Comprehensive Survey of Deep Research paper\"\n",
        "\n",
        "Action:\n",
        "- Arxiv returned A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\n",
        "- Tavily gave more details and confirmation\n",
        "\n",
        "Agent:\n",
        "- found authors\n",
        "- new calls to tavily for the 2 authors\n",
        "\n",
        "Action:\n",
        "- Retrieved current employment information for both authors\n",
        "\n",
        "Agent:\n",
        "- Compiled the findigs to a response\n",
        "2 full cycles (agent / action / agent / action / agent)\n",
        "\n",
        "\n",
        "\n",
        "Specifically my agent did the following:\n",
        "\n",
        "\n",
        "Receiving update from node: 'agent'\n",
        "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_givL2GsCYvC7NZj2J8Hl1yj1', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_35y5ynwQkKmguvhgZwoKjh98', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research paper\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 182, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73An3L0hHZQOPvcuQuXGfhjd3ZW', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4515e093-6840-42c1-a63e-ba1dc6d2728c-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_givL2GsCYvC7NZj2J8Hl1yj1', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research paper'}, 'id': 'call_35y5ynwQkKmguvhgZwoKjh98', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 59, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
        "\n",
        "\n",
        "\n",
        "Receiving update from node: 'action'\n",
        "Tool Used: arxiv\n",
        "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='c2f48b19-1489-4256-b33b-18b5333d3754', tool_call_id='call_givL2GsCYvC7NZj2J8Hl1yj1'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"|  |  |\\\\n --- |\\\\n| Comments: | 95 pages, 11 figures |\\\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\\\n| ACM classes: | I.2.8 |\\\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\\\n|  |  arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through\", \"score\": 0.88822687}, {\"title\": \"[PDF] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).\", \"score\": 0.8033131}, {\"title\": \"A comprehensive survey of deep learning research on medical ...\", \"url\": \"https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856\", \"content\": \"Skip to main contentSkip to article\\\\n\\\\nSign in\\\\n\\\\n Access through your organization\\\\n Purchase PDF\\\\n Patient Access\\\\n\\\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\\\n\\\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\\\n  \\\\n  \\\\nYou may also be able to exercise your privacy choices as described in our Privacy Policy\", \"score\": 0.5521781}, {\"title\": \"Top Research Papers on Deep Learning - Must Read List\", \"url\": \"https://paperguide.ai/papers/top/research-papers-deep-learning/\", \"content\": \"This is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support and the seminal work there.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Reading, Deep Learning\\\\n2 Citations 2022\\\\n\\\\nauthors unavailable\\\\n\\\\njournal unavailable [...] This paper surveys comprehensively recent advances in deep class-incremental learning and summarizes these methods from three aspects, i.e. , data-centric, model-centric, and algorithm-centric, and provides a rigorous and uniÔ¨Åed evaluation of 16 methods in benchmark image class-incremental learning tasks to find out the characteristics of different algorithms empirically.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Learning with Logical Constraints\\\\n62 Citations 2022 [...] IEEE Access\\\\n\\\\nThis paper comprehensively discussed the attacks and defenses in four popular DL models, including DNN, DRL, FL, and TL, and highlighted the application domains, datasets, metrics, and testbeds in these fields.\\\\n\\\\nChat\\\\n\\\\nCite\\\\n\\\\nReferences\\\\n\\\\n### Deep Class-Incremental Learning: A Survey\\\\n103 Citations 2023\\\\n\\\\nDa-Wei Zhou, Qiwen Wang, Zhi-Hong Qi + 3 more\\\\n\\\\nArXiv\", \"score\": 0.46337196}, {\"title\": \"Deep Research Tools: A Comprehensive Guide and Comparison\", \"url\": \"https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122\", \"content\": \"refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] ## Report Quality (Depth, Structure, Accuracy, Relevance)\\\\n\\\\nOne of the biggest considerations when choosing a deep research tool is the quality of the report or output it generates. Does it produce in-depth content or just superficial summaries? Are its reports well-structured and coherent? Does it stay accurate and cite relevant sources? Here‚Äôs how each tool fares: [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).\", \"score\": 0.45551404}]', name='tavily_search_results_json', id='ae6e0553-c3ce-477a-9db1-d67c035ca66a', tool_call_id='call_35y5ynwQkKmguvhgZwoKjh98', artifact={'query': 'A Comprehensive Survey of Deep Research paper', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research - arXiv', 'content': '|  |  |\\n --- |\\n| Comments: | 95 pages, 11 figures |\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\n| ACM classes: | I.2.8 |\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\n|  |  arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\n\\nFull-text links:\\n\\n## Access Paper: [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] > Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through', 'score': 0.88822687, 'raw_content': None}, {'url': 'https://arxiv.org/pdf/2506.12594?', 'title': '[PDF] A Comprehensive Survey of Deep Research - arXiv', 'content': 'Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] development, with specific attention to emerging architectures and integration opportunities The remainder of this paper follows a structured exploration beginning with conceptual frameworks (Section 2), technical innovations and comparative analysis (Sections 3-4), implementation technologies (Section 5), evaluation methodologies (Section 6), applications and use cases (Section 7), ethical considerations (Section 8), and future directions (Section 9).', 'score': 0.8033131, 'raw_content': None}, {'url': 'https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856', 'title': 'A comprehensive survey of deep learning research on medical ...', 'content': 'Skip to main contentSkip to article\\n\\nSign in\\n\\n Access through your organization\\n Purchase PDF\\n Patient Access\\n\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\n\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\n  \\n  \\nYou may also be able to exercise your privacy choices as described in our Privacy Policy', 'score': 0.5521781, 'raw_content': None}, {'url': 'https://paperguide.ai/papers/top/research-papers-deep-learning/', 'title': 'Top Research Papers on Deep Learning - Must Read List', 'content': 'This is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support and the seminal work there.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Reading, Deep Learning\\n2 Citations 2022\\n\\nauthors unavailable\\n\\njournal unavailable [...] This paper surveys comprehensively recent advances in deep class-incremental learning and summarizes these methods from three aspects, i.e. , data-centric, model-centric, and algorithm-centric, and provides a rigorous and uniÔ¨Åed evaluation of 16 methods in benchmark image class-incremental learning tasks to find out the characteristics of different algorithms empirically.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Learning with Logical Constraints\\n62 Citations 2022 [...] IEEE Access\\n\\nThis paper comprehensively discussed the attacks and defenses in four popular DL models, including DNN, DRL, FL, and TL, and highlighted the application domains, datasets, metrics, and testbeds in these fields.\\n\\nChat\\n\\nCite\\n\\nReferences\\n\\n### Deep Class-Incremental Learning: A Survey\\n103 Citations 2023\\n\\nDa-Wei Zhou, Qiwen Wang, Zhi-Hong Qi + 3 more\\n\\nArXiv', 'score': 0.46337196, 'raw_content': None}, {'url': 'https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122', 'title': 'Deep Research Tools: A Comprehensive Guide and Comparison', 'content': 'refine your query or add filters (like specifying a date range or field of study) and it will update the results near-instantly. The model‚Äôs summarization for each paper is done on the fly but it‚Äôs quite fast. One reason it‚Äôs speedy is that it doesn‚Äôt generate a huge narrative, it‚Äôs pulling bite-sized info (which is easier and quicker for an AI to produce). Also, much of the heavy lifting (searching papers) is done through efficient information retrieval systems. In short, among our list, [...] ## Report Quality (Depth, Structure, Accuracy, Relevance)\\n\\nOne of the biggest considerations when choosing a deep research tool is the quality of the report or output it generates. Does it produce in-depth content or just superficial summaries? Are its reports well-structured and coherent? Does it stay accurate and cite relevant sources? Here‚Äôs how each tool fares: [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).', 'score': 0.45551404, 'raw_content': None}], 'response_time': 1.63, 'request_id': '41cc526b-2883-4ac7-b1b3-3a7b9a670c5b'})]\n",
        "\n",
        "\n",
        "\n",
        "Receiving update from node: 'agent'\n",
        "[AIMessage(content='The paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" was published on June 14, 2025, authored by Renjun Xu and Jingwen Peng. \\n\\nI will now proceed to find out where the authors currently work.', additional_kwargs={'tool_calls': [{'id': 'call_ObzZFG5aVf8NAxQ058eg2d8h', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_KuvSnvV0DYPgSAFZMnxAqYLV', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 2574, 'total_tokens': 2686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73FKxf4Lf7DrH1et8k043TYbhAd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8fb80e27-78e4-421a-9c5e-9f702ae7cc23-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_ObzZFG5aVf8NAxQ058eg2d8h', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_KuvSnvV0DYPgSAFZMnxAqYLV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2574, 'output_tokens': 112, 'total_tokens': 2686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
        "\n",
        "\n",
        "\n",
        "Receiving update from node: 'action'\n",
        "Tool Used: tavily_search_results_json\n",
        "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University - OpenReview\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n#### Names\\\\n\\\\n#### Emails\\\\n\\\\n#### Personal Links\\\\n\\\\n#### Career & Education History\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n#### Expertise\\\\n\\\\n#### Publications\\\\n\\\\n#### scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics)\\\\n\\\\n#### $E(2)$-Equivariant Vision Transformer)\\\\n\\\\n#### Critical Temperature Prediction of Superconductors Based on Machine Learning: A Short Review) [...] #### Exploiting Adapters for Cross-Lingual Low-Resource Speech Recognition)\\\\n\\\\n#### Hierarchical knowledge amalgamation with dual discriminative feature alignment)\\\\n\\\\n#### Modeling Dynamic Missingness of Implicit Feedback for Sequential Recommendation)\\\\n\\\\n#### S2SNet: A Pretrained Neural Network for Superconductivity Discovery)\\\\n\\\\n#### Learning Interest-oriented Universal User Representation via Self-supervision) [...] #### Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling)\\\\n\\\\n#### Learning Invariant Representations across Domains and Tasks)\\\\n\\\\n#### Co-Authors\\\\n\\\\nOpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors. ¬© 2025 OpenReview\", \"score\": 0.6410185}, {\"title\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè\", \"url\": \"https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1\", \"content\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\\\n\\\\n\\\\n\\\\nResearch\\\\n\\\\nCenter for Data Science Zhejiang University\\\\n\\\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\\\n\\\\nEducation\\\\n\\\\nSign in to view more\\\\n\\\\nExperience\\\\n\\\\nSign in to view more [...] Research Interests\\\\n\\\\n2012 2025\\\\n\\\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\\\n\\\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\\\n\\\\nÊó∂Èó¥\\\\n\\\\nÂºïÁî®Èáè\\\\n\\\\n‰∏ªÈ¢ò\\\\n\\\\nÊúüÂàäÁ∫ßÂà´\\\\n\\\\nÂêà‰ΩúËÄÖ\\\\n\\\\nÂêà‰ΩúÊú∫ÊûÑ\\\\n\\\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\\\n\\\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\\\n\\\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\\\n\\\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\\\n\\\\nCited 0 Views 11 Bibtex\\\\n\\\\n0\\\\n\\\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\\\n\\\\nSwipe to Fine Result\", \"score\": 0.60049355}, {\"title\": \"Renjun Hu\\'s Homepage\", \"url\": \"https://hurenjun.github.io/\", \"content\": \"an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across various business\\\\ndomains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge.\\\\nSince January 2025, he has joined the School of Data Science and Engineering, East China Normal University\\\\nas a young researcher.\\\\nHis recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor\\'s degree in 2014 and Ph.D. in 2020 from the School of Computer Science\\\\nand Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student\\\\nin the Data Mining Group at Rutgers University. He then worked as a research intern at the Business\\\\nIntelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as [...] Renjun\\'s avatar\\\\n\\\\n### Renjun Hu     (ËÉ°‰ªÅÂêõ)\\\\n\\\\n#### Young Researcher\\\\n\\\\nSchool of Data Science of Engineering (DaSE)  \\\\nEast China Normal University (ECNU)\\\\n\\\\n \\\\nRoom X109, Shuxueguan, Putuo Campus\\\\n\\\\n \\\\nrjhu [at] dase.ecnu.edu.cn    renjun0hu [at] gmail.com\\\\n\\\\n### Short Bio\", \"score\": 0.59880555}, {\"title\": \"Renjun XU | UCD | Department of Physics | Research profile\", \"url\": \"https://www.researchgate.net/profile/Renjun-Xu\", \"content\": \"Skills and Expertise: Electronic Structure. Current institution: University of California, Davis. University of California, Davis.\", \"score\": 0.5683445}, {\"title\": \"Xu Genjun - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Xu_Genjun\", \"content\": \"Xu was born in She County, Anhui on 23 November 1935. He graduated from the Chemistry Department of Fudan University in 1957, and joined the Shanghai Institute of Biochemistry afterwards, where he participated in and made significant contributions to the insulin synthesis project led by Wang Yinglai. He later researched enzyme kinetics, chemical modification of proteins, the relationship between proteins\\' structure and function, and the folding and refolding of proteins. [...] Xu published more than 100 research papers in academic journals. He was a two-time winner of the State Natural Science Award (first class), in addition to several national prizes by the Chinese Academy of Sciences (CAS). He was also awarded the Ho Leung Ho Lee Prize for Life Sciences. He was elected as an academician of the CAS in 1991.\\\\n\\\\nXu died on 8 January 2008 at Zhongshan Hospital in Shanghai, at the age of 72.\\\\n\\\\n## References\\\\n\\\\nWikimedia Foundation\\\\nPowered by MediaWiki [...] Wikipedia\\\\nThe Free Encyclopedia\\\\n\\\\n## Contents\\\\n\\\\n# Xu Genjun\\\\n\\\\nXu Genjun (Chinese: ËÆ∏Ê†π‰øä; 23 November 1935 ‚Äì 8 January 2008) was a Chinese biochemist. He was a professor at the Shanghai Institute of Biochemistry and Cell Biology. He was an academician of the Chinese Academy of Sciences and President of the Chinese Society of Biochemistry and Molecular Biology.\\\\n\\\\n## Biography\", \"score\": 0.25375047}]', name='tavily_search_results_json', id='c5b33580-a980-4716-9472-ee857af9f2cc', tool_call_id='call_ObzZFG5aVf8NAxQ058eg2d8h', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University - OpenReview', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n#### Names\\n\\n#### Emails\\n\\n#### Personal Links\\n\\n#### Career & Education History\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n#### Expertise\\n\\n#### Publications\\n\\n#### scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics)\\n\\n#### $E(2)$-Equivariant Vision Transformer)\\n\\n#### Critical Temperature Prediction of Superconductors Based on Machine Learning: A Short Review) [...] #### Exploiting Adapters for Cross-Lingual Low-Resource Speech Recognition)\\n\\n#### Hierarchical knowledge amalgamation with dual discriminative feature alignment)\\n\\n#### Modeling Dynamic Missingness of Implicit Feedback for Sequential Recommendation)\\n\\n#### S2SNet: A Pretrained Neural Network for Superconductivity Discovery)\\n\\n#### Learning Interest-oriented Universal User Representation via Self-supervision) [...] #### Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling)\\n\\n#### Learning Invariant Representations across Domains and Tasks)\\n\\n#### Co-Authors\\n\\nOpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors. ¬© 2025 OpenReview', 'score': 0.6410185, 'raw_content': None}, {'url': 'https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1', 'title': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè', 'content': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\n\\n\\n\\nResearch\\n\\nCenter for Data Science Zhejiang University\\n\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\n\\nEducation\\n\\nSign in to view more\\n\\nExperience\\n\\nSign in to view more [...] Research Interests\\n\\n2012 2025\\n\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\n\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\n\\nÊó∂Èó¥\\n\\nÂºïÁî®Èáè\\n\\n‰∏ªÈ¢ò\\n\\nÊúüÂàäÁ∫ßÂà´\\n\\nÂêà‰ΩúËÄÖ\\n\\nÂêà‰ΩúÊú∫ÊûÑ\\n\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\n\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\n\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\n\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\n\\nCited 0 Views 11 Bibtex\\n\\n0\\n\\n11 [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\n\\nSwipe to Fine Result', 'score': 0.60049355, 'raw_content': None}, {'url': 'https://hurenjun.github.io/', 'title': \"Renjun Hu's Homepage\", 'content': \"an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across various business\\ndomains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge.\\nSince January 2025, he has joined the School of Data Science and Engineering, East China Normal University\\nas a young researcher.\\nHis recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor's degree in 2014 and Ph.D. in 2020 from the School of Computer Science\\nand Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student\\nin the Data Mining Group at Rutgers University. He then worked as a research intern at the Business\\nIntelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as [...] Renjun's avatar\\n\\n### Renjun Hu     (ËÉ°‰ªÅÂêõ)\\n\\n#### Young Researcher\\n\\nSchool of Data Science of Engineering (DaSE)  \\nEast China Normal University (ECNU)\\n\\n \\nRoom X109, Shuxueguan, Putuo Campus\\n\\n \\nrjhu [at] dase.ecnu.edu.cn    renjun0hu [at] gmail.com\\n\\n### Short Bio\", 'score': 0.59880555, 'raw_content': None}, {'url': 'https://www.researchgate.net/profile/Renjun-Xu', 'title': 'Renjun XU | UCD | Department of Physics | Research profile', 'content': 'Skills and Expertise: Electronic Structure. Current institution: University of California, Davis. University of California, Davis.', 'score': 0.5683445, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Xu_Genjun', 'title': 'Xu Genjun - Wikipedia', 'content': \"Xu was born in She County, Anhui on 23 November 1935. He graduated from the Chemistry Department of Fudan University in 1957, and joined the Shanghai Institute of Biochemistry afterwards, where he participated in and made significant contributions to the insulin synthesis project led by Wang Yinglai. He later researched enzyme kinetics, chemical modification of proteins, the relationship between proteins' structure and function, and the folding and refolding of proteins. [...] Xu published more than 100 research papers in academic journals. He was a two-time winner of the State Natural Science Award (first class), in addition to several national prizes by the Chinese Academy of Sciences (CAS). He was also awarded the Ho Leung Ho Lee Prize for Life Sciences. He was elected as an academician of the CAS in 1991.\\n\\nXu died on 8 January 2008 at Zhongshan Hospital in Shanghai, at the age of 72.\\n\\n## References\\n\\nWikimedia Foundation\\nPowered by MediaWiki [...] Wikipedia\\nThe Free Encyclopedia\\n\\n## Contents\\n\\n# Xu Genjun\\n\\nXu Genjun (Chinese: ËÆ∏Ê†π‰øä; 23 November 1935 ‚Äì 8 January 2008) was a Chinese biochemist. He was a professor at the Shanghai Institute of Biochemistry and Cell Biology. He was an academician of the Chinese Academy of Sciences and President of the Chinese Society of Biochemistry and Molecular Biology.\\n\\n## Biography\", 'score': 0.25375047, 'raw_content': None}], 'response_time': 1.67, 'request_id': '55198a01-11b8-40ed-bd45-2ad774234b55'}), ToolMessage(content='[{\"title\": \"Jingwen Peng, CFA - Director - Lead Data Steward at Liberty Mutual ...\", \"url\": \"https://www.linkedin.com/in/jingwen-peng-cfa-3a69b011?trk=public_profile_browsemap\", \"content\": \"Director - Lead Data Steward at Liberty Mutual Investments ¬∑ Experience: Liberty Mutual Investments ¬∑ Location: Boston ¬∑ 500+ connections on LinkedIn.\", \"score\": 0.70823324}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\\\n### Marketing Analyst  \\\\nEmpire City Casino  \\\\nMay 2025 - Present   \\\\nYonkers, New York, United States  \\\\n\\\\n### Amazon  \\\\nAmazon  \\\\nN/A - Present   \\\\nBeijing, China  \\\\n\\\\n### Marketing Analyst  \\\\nJiyuzhoutian Information Technology  \\\\nApr 2019 - Sep 2019   \\\\nBeijing, China  \\\\n‚óè\\\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.\", \"score\": 0.6301622}, {\"title\": \"[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018\", \"url\": \"https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf\", \"content\": \"Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE [...] over 10 villages in 4 provinces, interviewing over 600 people. He was appointed Academic Organizer of the China Youth Economic Forum and also served as the President of the Student Union of the School of Economics and the Chairman of the Standing Committee of the Students‚Äô Congress. Peng is 22 years old and from China. PRESTON LIM CANADA PRINCETON UNIVERSITY Preston graduated in June 2017 from Princeton University with a major in Near Eastern Studies and a minor in History and the Practice of\", \"score\": 0.38366494}, {\"title\": \"Professor Peng GONG - GEOG | HKU\", \"url\": \"https://geog.hku.hk/p-gong\", \"content\": \"Guan, D.\\\\\\\\, Wang, D., Hallegatte, S. Steven J. Davis, Jingwen Huo, Shuping Li, Yangchun Bai, Tianyang Lei, Qianyu Xue, D‚ÄôMaris Coffman, Danyang Cheng, Peipei Chen, Xi Liang, Bing Xu, Xiaosheng Lu, Shouyang Wang, Klaus Hubacek & Peng Gong. Global supply-chain effects of COVID-19 control measures. Nature Human Behaviour (2020). 4(6):577-587. . [...] Gong, P\\\\\\\\, Bin Chen, Xuecao Li, Han Liu, JieWang, Yuqi Bai, Jingming Chen, Xi Chen, Lei Fang, Shuailong Feng, Yongjiu Feng, Yali Gong, Hao Gu, Huabing Huang, Xiaochun Huang, Hongzan Jiao, Yingdong Kang, Guangbin Lei, Ainong Li, Xiaoting Li, Xun Li, Yuechen Li, Zhilin Li, Zhongde Li, Chong Liu, Chunxia Liu, Maochou Liu, Shuguang Liu, Wanliu Mao, Changhong Miao, Hao Ni, Qisheng Pan, Shuhua Qi, Zhehao Ren, Zhuoran Shan, Shaoqing Shen, Minjun Shi, Yimeng Song, Mo Su, HoiPing Suen, Bo Sun, Fangdi [...] Beijing Normal University, and the Tsinghua Urban Institute at Tsinghua University. In 2020, he led an expert preparation group in establishing the Vanke School of Public Health at Tsinghua.\", \"score\": 0.30464175}, {\"title\": \"Investigators | Center for Computational Biology and Bioinformatics\", \"url\": \"https://medicine.iu.edu/research-centers/computational-biology-bioinformatics/investigators\", \"content\": \"Associate Professor of Bioinformatics and Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Bohdan Khomtchouk, PhD\\\\n\\\\nAssistant Professor of Bioinformatics and Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Juexin Wang, PhD\\\\n\\\\nAssistant Professor of Bioinformatics\\\\n\\\\nRead Bio\\\\n\\\\n### Jingwen Yan, PhD\\\\n\\\\nAssistant Professor of Bioinformatics\\\\n\\\\nRead Bio\\\\n\\\\n### IU Bloomington Luddy School of Informatics, Computing and Engineering\\\\n\\\\n### Yijie Wang, PhD\\\\n\\\\nAssistant Professor of Computer Science\\\\n\\\\nRead Bio\\\\n\\\\n### Purdue University in Indianapolis [...] ### Jing Liu, PhD\\\\n\\\\nAssistant Professor of Physics\\\\n\\\\nRead Bio\\\\n\\\\n## Associate Members\\\\n\\\\nJunior computational scientists conducting research in quantitative biomedical sciences\\\\n\\\\n### Xiaoqing Huang, PhD\\\\n\\\\nAssistant Research Professor of Biostatistics & Health Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Gang Peng, PhD\\\\n\\\\nAssistant Professor of Medical & Molecular Genetics\\\\n\\\\nRead Bio\\\\n\\\\n### Jie Ren, PhD\\\\n\\\\nAssistant Professor of Biostatistics & Health Data Science\\\\n\\\\nRead Bio\\\\n\\\\n### Tae-Hwi L. Schwantes-An, PhD [...] Professor of Biochemistry & Molecular Biology\\\\n\\\\nRead Bio\\\\n\\\\n### Ian Webb, PhD\\\\n\\\\nAssistant Professor, Department of Chemistry & Chemical Biology\\\\n\\\\nRead Bio\\\\n\\\\n### Kai Yang, PhD\\\\n\\\\nAssociate Professor of Pediatrics\\\\n\\\\nRead Bio\\\\n\\\\n### Lei Yang, PhD\\\\n\\\\nProfessor of Pediatrics\\\\n\\\\nRead Bio\\\\n\\\\n### Ji Zhang, PhD\\\\n\\\\nAssociate Professor of Pediatrics\\\\n\\\\nRead Bio\", \"score\": 0.19255488}]', name='tavily_search_results_json', id='2efa1c1e-58d6-4af2-8c57-ea2e8323e1c1', tool_call_id='call_KuvSnvV0DYPgSAFZMnxAqYLV', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.linkedin.com/in/jingwen-peng-cfa-3a69b011?trk=public_profile_browsemap', 'title': 'Jingwen Peng, CFA - Director - Lead Data Steward at Liberty Mutual ...', 'content': 'Director - Lead Data Steward at Liberty Mutual Investments ¬∑ Experience: Liberty Mutual Investments ¬∑ Location: Boston ¬∑ 500+ connections on LinkedIn.', 'score': 0.70823324, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn', 'content': '‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\n### Marketing Analyst  \\nEmpire City Casino  \\nMay 2025 - Present   \\nYonkers, New York, United States  \\n\\n### Amazon  \\nAmazon  \\nN/A - Present   \\nBeijing, China  \\n\\n### Marketing Analyst  \\nJiyuzhoutian Information Technology  \\nApr 2019 - Sep 2019   \\nBeijing, China  \\n‚óè\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.', 'score': 0.6301622, 'raw_content': None}, {'url': 'https://www.schwarzmanscholars.org/wp-content/uploads/2020/05/Schwarzman-Scholars-Class-of-2018-profiles-126-Scholars.pdf', 'title': '[PDF] SCHWARZMAN SCHOLARS CLASS OF 2018', 'content': 'Jingwen SUN graduated in May 2017 from the National University of Singapore with a Bachelor‚Äôs degree in Computing and Business. She is passionate about innovation and entrepreneurship. She has worked with venture capital funds in Israel and China and also worked with Accenture and Analysys Mason as an analyst intern. Jingwen is excited to join the Schwarzman Scholars program to learn more about leadership within a global context. Jingwen is 23 years old and from China. JONATHAN PADILLA UNITED [...] Assistant at Purdue, supporting both domestic and international students, and served as Vice President of Alpha Kappa Psi. She most recently worked in the Risk Assurance practice at PricewaterhouseCoopers in Chicago. At Schwarzman College, she aspires to amplify her leadership and business skills as both a humanitarian and an entrepreneur to improve and empower the education of youth in developing regions. Jing is 24 years old and from China. JINGWEN SUN CHINA NATIONAL UNIVERSITY OF SINGAPORE [...] over 10 villages in 4 provinces, interviewing over 600 people. He was appointed Academic Organizer of the China Youth Economic Forum and also served as the President of the Student Union of the School of Economics and the Chairman of the Standing Committee of the Students‚Äô Congress. Peng is 22 years old and from China. PRESTON LIM CANADA PRINCETON UNIVERSITY Preston graduated in June 2017 from Princeton University with a major in Near Eastern Studies and a minor in History and the Practice of', 'score': 0.38366494, 'raw_content': None}, {'url': 'https://geog.hku.hk/p-gong', 'title': 'Professor Peng GONG - GEOG | HKU', 'content': 'Guan, D.\\\\, Wang, D., Hallegatte, S. Steven J. Davis, Jingwen Huo, Shuping Li, Yangchun Bai, Tianyang Lei, Qianyu Xue, D‚ÄôMaris Coffman, Danyang Cheng, Peipei Chen, Xi Liang, Bing Xu, Xiaosheng Lu, Shouyang Wang, Klaus Hubacek & Peng Gong. Global supply-chain effects of COVID-19 control measures. Nature Human Behaviour (2020). 4(6):577-587. . [...] Gong, P\\\\, Bin Chen, Xuecao Li, Han Liu, JieWang, Yuqi Bai, Jingming Chen, Xi Chen, Lei Fang, Shuailong Feng, Yongjiu Feng, Yali Gong, Hao Gu, Huabing Huang, Xiaochun Huang, Hongzan Jiao, Yingdong Kang, Guangbin Lei, Ainong Li, Xiaoting Li, Xun Li, Yuechen Li, Zhilin Li, Zhongde Li, Chong Liu, Chunxia Liu, Maochou Liu, Shuguang Liu, Wanliu Mao, Changhong Miao, Hao Ni, Qisheng Pan, Shuhua Qi, Zhehao Ren, Zhuoran Shan, Shaoqing Shen, Minjun Shi, Yimeng Song, Mo Su, HoiPing Suen, Bo Sun, Fangdi [...] Beijing Normal University, and the Tsinghua Urban Institute at Tsinghua University. In 2020, he led an expert preparation group in establishing the Vanke School of Public Health at Tsinghua.', 'score': 0.30464175, 'raw_content': None}, {'url': 'https://medicine.iu.edu/research-centers/computational-biology-bioinformatics/investigators', 'title': 'Investigators | Center for Computational Biology and Bioinformatics', 'content': 'Associate Professor of Bioinformatics and Data Science\\n\\nRead Bio\\n\\n### Bohdan Khomtchouk, PhD\\n\\nAssistant Professor of Bioinformatics and Data Science\\n\\nRead Bio\\n\\n### Juexin Wang, PhD\\n\\nAssistant Professor of Bioinformatics\\n\\nRead Bio\\n\\n### Jingwen Yan, PhD\\n\\nAssistant Professor of Bioinformatics\\n\\nRead Bio\\n\\n### IU Bloomington Luddy School of Informatics, Computing and Engineering\\n\\n### Yijie Wang, PhD\\n\\nAssistant Professor of Computer Science\\n\\nRead Bio\\n\\n### Purdue University in Indianapolis [...] ### Jing Liu, PhD\\n\\nAssistant Professor of Physics\\n\\nRead Bio\\n\\n## Associate Members\\n\\nJunior computational scientists conducting research in quantitative biomedical sciences\\n\\n### Xiaoqing Huang, PhD\\n\\nAssistant Research Professor of Biostatistics & Health Data Science\\n\\nRead Bio\\n\\n### Gang Peng, PhD\\n\\nAssistant Professor of Medical & Molecular Genetics\\n\\nRead Bio\\n\\n### Jie Ren, PhD\\n\\nAssistant Professor of Biostatistics & Health Data Science\\n\\nRead Bio\\n\\n### Tae-Hwi L. Schwantes-An, PhD [...] Professor of Biochemistry & Molecular Biology\\n\\nRead Bio\\n\\n### Ian Webb, PhD\\n\\nAssistant Professor, Department of Chemistry & Chemical Biology\\n\\nRead Bio\\n\\n### Kai Yang, PhD\\n\\nAssociate Professor of Pediatrics\\n\\nRead Bio\\n\\n### Lei Yang, PhD\\n\\nProfessor of Pediatrics\\n\\nRead Bio\\n\\n### Ji Zhang, PhD\\n\\nAssociate Professor of Pediatrics\\n\\nRead Bio', 'score': 0.19255488, 'raw_content': None}], 'response_time': 1.63, 'request_id': '429125b7-11e4-4b4c-8cff-22a6734a27c4'})]\n",
        "\n",
        "\n",
        "\n",
        "Receiving update from node: 'agent'\n",
        "[AIMessage(content='Renjun Xu is currently a Principal Researcher at Zhejiang University and also associated with the Center for Data Science at Zhejiang University. Jingwen Peng is a Director and Lead Data Steward at Liberty Mutual Investments in Boston.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 6331, 'total_tokens': 6374, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2560}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ73IQm6GxBQWegjfZQiI2Czy1e7O', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--df884874-cc42-4bb4-ae70-588654a0f6be-0', usage_metadata={'input_tokens': 6331, 'output_tokens': 43, 'total_tokens': 6374, 'input_token_details': {'audio': 0, 'cache_read': 2560}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Deep Research typically refers to an in-depth and comprehensive investigation or analysis into a specific topic, subject, or field. It involves thorough examination of available data, literature, and resources to uncover detailed insights, understand complex issues, and generate new knowledge or solutions. Deep Research is often characterized by rigorous methodology, critical thinking, and a focus on uncovering underlying principles or patterns.\\n\\nIf you are referring to a specific organization, product, or context named \"Deep Research,\" please provide more details so I can give a more precise answer.'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
        "\n",
        "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
        "    },\n",
        "    ...,\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"How do people use AI in their daily work?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"work\", \"productivity\", \"automation\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What are the most common ways people use AI in their work?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"writing\", \"analysis\", \"coding\", \"automation\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"Do people use AI for their personal lives?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"personal\", \"learning\", \"entertainment\", \"planning\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What concerns or challenges do people have when using AI?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"privacy\", \"accuracy\", \"bias\", \"job\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What should I build to add value to the local communities I'm engaged in?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"community\", \"education\", \"accessibility\", \"local\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"What AI projects should companies build first to maximize ROI?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"ROI\", \"automation\", \"efficiency\", \"customer\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\": {\"text\": \"How can AI help with customer service and support?\"},\n",
        "        \"outputs\": {\"must_mention\": [\"customer\", \"support\", \"response\", \"automation\"]}\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key set: True\n"
          ]
        },
        {
          "ename": "LangSmithError",
          "evalue": "Failed to POST /datasets in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Forbidden\"}')",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langsmith/utils.py:159\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langsmith/client.py:937\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    931\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    932\u001b[39m         method,\n\u001b[32m    933\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    934\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    935\u001b[39m         **request_kwargs,\n\u001b[32m    936\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langsmith/utils.py:161\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mHTTPError\u001b[39m: [Errno 403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Forbidden\"}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mLangSmithError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m dataset_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimple Search Agent - Evaluation Dataset - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid4().hex[\u001b[32m0\u001b[39m:\u001b[32m8\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAPI key set:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_API_KEY\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQuestions about the cohort use-case to evaluate the Simple Search Agent.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m client.create_examples(\n\u001b[32m     13\u001b[39m     dataset_id=dataset.id,\n\u001b[32m     14\u001b[39m     examples=questions\n\u001b[32m     15\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langsmith/client.py:3801\u001b[39m, in \u001b[36mClient.create_dataset\u001b[39m\u001b[34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[39m\n\u001b[32m   3798\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3799\u001b[39m     dataset[\u001b[33m\"\u001b[39m\u001b[33moutputs_schema_definition\u001b[39m\u001b[33m\"\u001b[39m] = outputs_schema\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3805\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_orjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3807\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3809\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas.Dataset(\n\u001b[32m   3810\u001b[39m     **response.json(),\n\u001b[32m   3811\u001b[39m     _host_url=\u001b[38;5;28mself\u001b[39m._host_url,\n\u001b[32m   3812\u001b[39m     _tenant_id=\u001b[38;5;28mself\u001b[39m._get_optional_tenant_id(),\n\u001b[32m   3813\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/AIE8/05_Our_First_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langsmith/client.py:997\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n\u001b[32m    996\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    998\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    999\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1000\u001b[39m     )\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m   1003\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1004\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1005\u001b[39m     )\n",
            "\u001b[31mLangSmithError\u001b[39m: Failed to POST /datasets in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Forbidden\"}')"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
        "\n",
        "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A correct answer:\n",
            "  - Provides accurate and complete information\n",
            "  - Contains no factual errors\n",
            "  - Addresses all parts of the question\n",
            "  - Is logically consistent\n",
            "  - Uses precise and accurate terminology\n",
            "\n",
            "  When scoring, you should penalize:\n",
            "  - Factual errors or inaccuracies\n",
            "  - Incomplete or partial answers\n",
            "  - Misleading or ambiguous statements\n",
            "  - Incorrect terminology\n",
            "  - Logical inconsistencies\n",
            "  - Missing key information\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output\n",
            "  - Check for factual accuracy and completeness\n",
            "  - Focus on correctness of information rather than style or verbosity\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to evaluate factual correctness and completeness of the response.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n",
            "Use the reference outputs below to help you evaluate the correctness of the response:\n",
            "\n",
            "<reference_outputs>\n",
            "{reference_outputs}\n",
            "</reference_outputs>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openevals.prompts import CORRECTNESS_PROMPT\n",
        "print(CORRECTNESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from openevals.llm import create_llm_as_judge\n",
        "\n",
        "correctness_evaluator = create_llm_as_judge(\n",
        "        prompt=CORRECTNESS_PROMPT,\n",
        "        model=\"openai:o3-mini\", # very impactful to the final score\n",
        "        feedback_key=\"correctness\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "  # determine if the phrases in the reference_outputs are in the outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'simple_agent, baseline-4085d794' at:\n",
            "https://smith.langchain.com/o/340cd80b-3296-5752-9a9e-58582118073a/datasets/cd9ccfce-ebdd-4b2b-8c53-53df5a7a341b/compare?selectedSessions=6e4899d9-d28a-4008-8ffc-3e7883e9ef07\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9819a2b30c94b62b2a4cb83c615c784",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    evaluators=[correctness_evaluator, must_mention],\n",
        "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
        "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
        "    max_concurrency=4, # optional, add concurrency\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rN7feNVn9f"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r6XXA5FJbVf",
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ22o2mWVrfp"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNWHwWxuRiLY",
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x75bc729039d0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "##### YOUR MARKDOWN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Deep Research Agents are advanced AI systems designed to assist with in-depth research tasks. They leverage deep learning techniques and large datasets to analyze complex information, generate insights, and support decision-making across various fields such as science, technology, medicine, and more. These agents can automate literature reviews, extract relevant data from vast sources, and provide comprehensive summaries, making research more efficient and thorough. Would you like me to find more detailed or specific information about Deep Research Agents?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 158, 'total_tokens': 251, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CJ4p3pIKceAjbeS3g3QtsJLgucObk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b10b2082-4074-4d48-848f-37d11d18949b-0', usage_metadata={'input_tokens': 158, 'output_tokens': 93, 'total_tokens': 251, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
        "\n",
        "Let's ask our system about the 3 main patterns in Generative AI:\n",
        "\n",
        "1. Context Engineering\n",
        "2. Fine-tuning\n",
        "3. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context Engineering is a relatively new interdisciplinary field that focuses on designing, managing, and optimizing the context in which systems, especially artificial intelligence and software applications, operate. It involves understanding and shaping the environment, circumstances, and background information that influence how systems behave and interact with users. The goal is to improve system performance, user experience, and decision-making by carefully engineering the context.\n",
            "\n",
            "The concept of Context Engineering has gained prominence with the rise of AI, IoT, and complex software systems, where context plays a crucial role in system effectiveness. It started to break onto the scene in the late 2010s and early 2020s, driven by advancements in contextual AI, ubiquitous computing, and the need for more adaptive and personalized systems.\n",
            "\n",
            "Would you like me to find more detailed or specific information about its origins and development?\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has already learned general features from a large dataset and then further training it on a smaller, task-specific dataset. This process helps the model specialize and improve its performance on the target task while leveraging the knowledge it has already acquired.\n",
            "\n",
            "Fine-tuning has become a prominent approach in the development of large language models, computer vision models, and other deep learning architectures. It allows researchers and developers to efficiently customize models for various applications, such as natural language processing, image recognition, and more.\n",
            "\n",
            "As for when it \"broke onto the scene,\" fine-tuning has been around in various forms for many years, but it gained widespread popularity and recognition with the rise of large pre-trained models like BERT (introduced in 2018) and GPT (with GPT-2 in 2019 and GPT-3 in 2020). These models demonstrated the effectiveness of transfer learning and fine-tuning, leading to a significant shift in how AI models are developed and deployed.\n",
            "\n",
            "Would you like me to find more detailed historical information or specific milestones related to the development of fine-tuning?\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are intelligent systems that leverage large language models (LLMs) to perform a variety of tasks, such as understanding natural language, generating human-like responses, and making decisions or taking actions based on the input they receive. These agents can be used in applications like chatbots, virtual assistants, automated customer support, and more complex decision-making systems.\n",
            "\n",
            "The concept of LLM-based agents gained significant attention and broke onto the scene around 2020-2021, coinciding with the development and release of advanced large language models like OpenAI's GPT-3 in 2020. GPT-3's impressive capabilities demonstrated the potential of LLMs to serve as foundational components for building intelligent agents that can understand and generate human language at a high level.\n",
            "\n",
            "Since then, the field has rapidly evolved, with numerous innovations in model architecture, training techniques, and applications, making LLM-based agents a prominent area of research and development in artificial intelligence.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
